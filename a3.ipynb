{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from scipy.spatial.distance import cdist\n",
    "from time import time\n",
    "import itertools\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, accuracy_score\n",
    "\n",
    "from sklearn.datasets import load_iris, load_digits, load_breast_cancer\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "colors = ['#0D76BF', '#00cc96', '#EF553B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd_df(data, label='label'):\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    df_X = pd.DataFrame(data=X, columns=data.feature_names)\n",
    "    df_y = pd.DataFrame(data=y, columns=[label])\n",
    "    df = pd.concat([df_X, df_y], axis=1)\n",
    "    return df, df_X, df_y\n",
    "\n",
    "def plot_decn_bdry(X, y, model_class, **model_params):\n",
    "    \"\"\"Function to plot the decision boundaries of a classification model.\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    X_t = pca.fit_transform(X)\n",
    "    \n",
    "    model = model_class(**model_params)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Step size of the mesh\n",
    "    h = .02 \n",
    "\n",
    "    # Plot the decision boundary in 2 dimensions\n",
    "    x_min, x_max = X_t[:, 0].min() - .5, X_t[:, 0].max() + .5\n",
    "    y_min, y_max = X_t[:, 1].min() - .5, X_t[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Obtain labels for each point in mesh using the model.\n",
    "    dstacked = np.dstack((xx, yy))\n",
    "    shape_t = (xx.shape[0] * xx.shape[1], X.shape[1])\n",
    "    predict_data = pca.inverse_transform(dstacked).reshape(shape_t)\n",
    "    Z = model.predict(predict_data).reshape(xx.shape) \n",
    "\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X_t[:, 0], X_t[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "    return plt\n",
    "\n",
    "def get_freq_plot(df, col):\n",
    "    val_cnt_df = pd.DataFrame(df[col].value_counts())\n",
    "    freq_data = val_cnt_df.reset_index().rename(columns={'index': 'value', col:'count'})\n",
    "    ax = sns.barplot(x=\"value\", y=\"count\",data=freq_data)\n",
    "    \n",
    "def set_split(df, label):\n",
    "    X = df[[col for col in df.columns if col != label]]\n",
    "    y = df[label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_test_score(X_train, y_train, X_test, y_test, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    test_score = clf.score(X_test, y_test)\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "label = 'diagnosis'\n",
    "cols_X = data.feature_names\n",
    "# X, y = data.data, data.target\n",
    "# print(X.shape, y.shape)\n",
    "print(list(data.target_names))\n",
    "df, X, y = get_pd_df(data, label=label)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red = pd.read_csv('wine-quality/winequality-red.csv', sep=';')\n",
    "df_red['is_red_wine'] = 1\n",
    "df_white = pd.read_csv('wine-quality/winequality-white.csv', sep=';')\n",
    "df_white['is_red_wine'] = 0\n",
    "df = pd.concat([df_red, df_white], axis = 0).reset_index(drop=True)\n",
    "label = 'is_red_wine'\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "cols_X = [col for col in df.columns if col != label]\n",
    "X = df[cols_X]\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(range_n_clusters, estimator):\n",
    "    ssd, sc = [], []\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Create a subplot with 1 row and 2 columns\n",
    "        fig, (ax1) = plt.subplots(1, 1)\n",
    "        fig.set_size_inches(10, 5)\n",
    "\n",
    "        # The 1st subplot is the silhouette plot\n",
    "        # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "        # lie within [-0.1, 1]\n",
    "        ax1.set_xlim([-0.1, 1])\n",
    "        # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "        # plots of individual clusters, to demarcate them clearly.\n",
    "        ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "        # Initialize the clusterer with n_clusters value and a random generator\n",
    "        # seed of 10 for reproducibility.\n",
    "        \n",
    "        clusterer = estimator(n_clusters, random_state=10)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        if clusterer.__class__.__name__ == 'KMeans':\n",
    "            ssd_n = clusterer.inertia_\n",
    "        else:     \n",
    "            ssd_n = sum(np.min(cdist(X, clusterer.means_, 'euclidean'), axis=1)) / X.shape[0]\n",
    "        ssd.append(ssd_n)\n",
    "\n",
    "        # The silhouette_score gives the average value for all the samples.\n",
    "        # This gives a perspective into the density and separation of the formed\n",
    "        # clusters\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        sc.append(silhouette_avg)\n",
    "        print(\"For n_clusters =\", n_clusters,\n",
    "              \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "        # Compute the silhouette scores for each sample\n",
    "        sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            # Aggregate the silhouette scores for samples belonging to\n",
    "            # cluster i, and sort them\n",
    "            ith_cluster_silhouette_values = \\\n",
    "                sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                              0, ith_cluster_silhouette_values,\n",
    "                              facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            # Label the silhouette plots with their cluster numbers at the middle\n",
    "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            # Compute the new y_lower for next plot\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "        # The vertical line for average silhouette score of all the values\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                      \"with n_clusters = %d\" % n_clusters),\n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "    # plt.show()\n",
    "    return(ssd, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = make_pipeline(StandardScaler(), KMeans(n_clusters=4))\n",
    "# X_c = pipe.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "range_n_clusters = list(range(2, 10)) + list(range(10, 40, 5))\n",
    "ssd, sc = plot_clusters(range_n_clusters, GaussianMixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range_n_clusters, ssd, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range_n_clusters, sc, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('SC')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "n_components_range = range_n_clusters\n",
    "sc, ssd = [], []\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "for cv_type in cv_types:\n",
    "    sc, ssd = [], []\n",
    "    for n_components in n_components_range:\n",
    "        gmm = GaussianMixture(n_components=n_components, covariance_type=cv_type)\n",
    "        gmm.fit(X)\n",
    "        cluster_labels = gmm.predict(X)\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        ssd_n = sum(np.min(cdist(X, gmm.means_, 'euclidean'), axis=1)) / X.shape[0]\n",
    "        sc.append(silhouette_avg)\n",
    "        ssd.append(ssd_n)\n",
    "    \n",
    "    plt1 = plt.subplot(1, 2, 2)\n",
    "    plt1.plot(n_components_range, sc, 'x-', label=cv_type)\n",
    "    plt1.legend(loc='upper right')\n",
    "    plt1.set_xlabel('number of clusters')\n",
    "    plt1.set_ylabel('Silhoutte Score')\n",
    "    \n",
    "    plt2 = plt.subplot(1, 2, 1)\n",
    "    plt2.plot(n_components_range, ssd, 'x-', label=cv_type)\n",
    "    plt2.legend(loc='upper right')\n",
    "    plt2.set_xlabel('number of clusters')\n",
    "    plt2.set_ylabel('Sum of Squared Error')\n",
    "\n",
    "plt.subplots_adjust(hspace=.35, bottom=.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce down to 2 dimensions and visualize between labels\n",
    "n_clusters = 3\n",
    "clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "cluster_labels = clusterer.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_t, columns=['x', 'y']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reduced_to_2d(pipeline, X, y):\n",
    "    X_t = pipeline.fit_transform(X)\n",
    "    X_t_y_df = pd.concat([pd.DataFrame(X_t, columns=['x', 'y']), y], axis=1)\n",
    "    trace = go.Scattergl(\n",
    "        x = X_t_y_df.x, \n",
    "        y = X_t_y_df.y,\n",
    "        mode = 'markers',\n",
    "        marker=dict(\n",
    "            color = X_t_y_df[label],\n",
    "            colorscale = [[0, 'green'], [1, 'red']],\n",
    "            showscale = True,\n",
    "            opacity = 0.8\n",
    "        )\n",
    "    ) \n",
    "\n",
    "    # Plot and embed in ipython notebook!\n",
    "    iplot([trace], filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 =time()\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA(n_components=2))\n",
    "visualize_reduced_to_2d(pca_pipe, X, y)\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scattergl(\n",
    "    x = X_t_y_df.x, \n",
    "    y = X_t_y_df.y,\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        color = cluster_labels,\n",
    "        symbol = X_t_y_df[label],\n",
    "        colorscale = 'Jet',\n",
    "        showscale = True,\n",
    "        opacity = 0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "iplot(data, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.DataFrame(cluster_labels, columns=['cluster'])\n",
    "df_w_cluster = pd.concat([df, df_cluster], axis=1)\n",
    "df_w_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X_std = pd.DataFrame(X_std, columns=cols_X)\n",
    "df_std_w_cluster = pd.concat([X_std, y, df_cluster], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_std_w_cluster\n",
    "df_plot_mean = df_plot.groupby(['cluster']).mean()\n",
    "df_plot_std = df_plot.groupby(['cluster']).std()\n",
    "df_plot_mean_plus_std = df_plot + df_w_cluster_std\n",
    "df_plot_mean_minus_std = df_plot - df_w_cluster_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = [go.Scatter(\n",
    "    x = df_plot_mean.columns,\n",
    "    y = df_plot_mean.iloc[i,:],\n",
    "    mode = 'markers',\n",
    "    name = 'cluster {}'.format(i),\n",
    "    marker = dict(opacity = 0.8)\n",
    ") for i in range(n_clusters)]\n",
    "\n",
    "\n",
    "data = traces\n",
    "# data = [trace0, trace1, trace2]\n",
    "\n",
    "iplot(data, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        'y': df_plot[df_plot.cluster == i].values.flatten(order='F'),\n",
    "        'x': np.repeat(df_plot.columns, df_plot[df_plot.cluster == i].shape[0]),\n",
    "        'name' : 'cluster {}'.format(i),\n",
    "        'marker': {\n",
    "            'opacity': .9\n",
    "        },\n",
    "        'boxmean': True,\n",
    "        'boxpoints' : False,\n",
    "        'orientation': 'v',\n",
    "        \"type\": \"box\",\n",
    "    } for i in range(n_clusters)\n",
    "]\n",
    "layout = {\n",
    "    'yaxis': {\n",
    "        'title': 'features',\n",
    "        'zeroline': False,\n",
    "        'range': [-2, 5]\n",
    "    },\n",
    "    'boxmode': 'group'\n",
    "\n",
    "}\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_data_w_dim_reducer(X, estimator, n_components):\n",
    "    scaler = StandardScaler()\n",
    "    X_s = scaler.fit_transform(X)\n",
    "\n",
    "    t0 = time()\n",
    "    transformer = estimator(n_components=n_components)\n",
    "    X_t = transformer.fit_transform(X_s)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    X_r = transformer.inverse_transform(X_t)\n",
    "    X_r = scaler.inverse_transform(X_r)\n",
    "    \n",
    "    df_r = pd.DataFrame(X_r, columns=X.columns)\n",
    "    return {'df':df_r, 'components':transformer.components_}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = recreate_data_w_dim_reducer(X, PCA, 2)['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "X_std = pd.DataFrame(X_std, columns=cols_X)\n",
    "data = [go.Box(y=X_std[col], name=col) for col in X_std.columns.tolist()]\n",
    "iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_new_std = scaler.fit_transform(X_new)\n",
    "X_new_std = pd.DataFrame(X_new_std, columns=cols_X)\n",
    "data = [go.Box(y=X_new_std[col], name=col) for col in X_new.columns.tolist()]\n",
    "iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        'y': df[df.cluster == i].values.flatten(order='F'),\n",
    "        'x': np.repeat(df_plot.columns, df_plot[df_plot.cluster == i].shape[0]),\n",
    "        'name' : 'cluster {}'.format(i),\n",
    "        'marker': {\n",
    "            'opacity': .9\n",
    "        },\n",
    "        'boxmean': True,\n",
    "        'boxpoints' : False,\n",
    "        'orientation': 'v',\n",
    "        \"type\": \"box\",\n",
    "    } for df in [df1, df2]\n",
    "]\n",
    "layout = {\n",
    "    'yaxis': {\n",
    "        'title': 'features',\n",
    "        'zeroline': False,\n",
    "        'range': [-2, 5]\n",
    "    },\n",
    "    'boxmode': 'group'\n",
    "\n",
    "}\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of variance explained\n",
    "scaler = StandardScaler()\n",
    "X_s = scaler.fit_transform(X)\n",
    "\n",
    "t0 = time()\n",
    "pca = PCA()\n",
    "X_t = pca.fit_transform(X_s)\n",
    "plt.plot(transformer.explained_variance_ratio_, 'bx-')\n",
    "# shoulder at 3 or 4 then at 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals = transformer.explained_variance_\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "trace1 = dict(\n",
    "    type='bar',\n",
    "    x=['PC %s' %i for i in range(1,10)],\n",
    "    y=var_exp,\n",
    "    name='Individual'\n",
    ")\n",
    "\n",
    "trace2 = dict(\n",
    "    type='scatter',\n",
    "    x=['PC %s' %i for i in range(1,10)], \n",
    "    y=cum_var_exp,\n",
    "    name='Cumulative'\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "\n",
    "layout=dict(\n",
    "    title='Explained variance by different principal components',\n",
    "    yaxis=dict(\n",
    "        title='Explained variance in percent'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='selecting-principal-components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA()\n",
    "X_t = ica.fit_transform(X_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "pca_pipe = make_pipeline(StandardScaler(), FastICA(n_components=2))\n",
    "visualize_reduced_to_2d(pca_pipe, X, y)\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X.shape[0]\n",
    "# We center the data and compute the sample covariance matrix.\n",
    "X -= np.mean(X, axis=0)\n",
    "cov_matrix = np.dot(X.T, X) / n_samples\n",
    "for eigenvector in ica.components_:\n",
    "    print(np.dot(eigenvector.T, np.dot(cov_matrix, eigenvector)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. RP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "rp_pipe = make_pipeline(StandardScaler(), GaussianRandomProjection(n_components=2, random_state=12))\n",
    "visualize_reduced_to_2d(rp_pipe, X, y)\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "pipe = make_pipeline(StandardScaler(), Isomap(n_components=2))\n",
    "visualize_reduced_to_2d(pipe, X, y)\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dim Reduce then Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "X_s = StandardScaler().fit_transform(X)\n",
    "X_t = PCA(n_components=2).fit_transform(X_s)\n",
    "# evaluate how good are the clustering? Same clusters as before? Why or why not?\n",
    "X_c = KMeans(n_clusters=3).fit_predict(X_t)\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scattergl(\n",
    "    x = X_t[:,0], \n",
    "    y = X_t[:,1],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        color = X_c,\n",
    "        symbol = y,\n",
    "        colorscale = 'Jet',\n",
    "        showscale = True,\n",
    "        opacity = 0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "iplot(data, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dim Reduce then NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance and Run speed reduction etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_pipeline = make_pipeline(StandardScaler(), PCA(n_components=7), MLPClassifier(hidden_layer_sizes=[16,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "estimator_pipeline.fit(X_train, y_train)\n",
    "y_pred = estimator_pipeline.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wine-quality/winequality-red.csv', sep=';')\n",
    "label = 'quality'\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if label == 'quality':\n",
    "    df[label] = df[label].map(lambda x: 0 if x in [3, 4, 5] else 1)\n",
    "get_freq_plot(df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = set_split(df, 'quality')\n",
    "estimator_pipeline.fit(X_train, y_train)\n",
    "y_pred = estimator_pipeline.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dim Reduce then Cluster then NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
